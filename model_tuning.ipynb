{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.8 64-bit ('yolov4': conda)",
   "display_name": "Python 3.6.8 64-bit ('yolov4': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e97901242f88c265f8332d1e188065dc1895b0b2e559198b8221f35047a478de"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: future in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (0.18.2)\n",
      "Requirement already satisfied: terminaltables in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (0.4.3)\n",
      "Requirement already satisfied: requests in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (2.24.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (4.48.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (0.8.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from keras-tuner) (1.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from requests->keras-tuner) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from requests->keras-tuner) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from scikit-learn->keras-tuner) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from scikit-learn->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: hiplot in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (0.1.19)\n",
      "Requirement already satisfied: flask in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from hiplot) (1.1.2)\n",
      "Requirement already satisfied: ipython>=7.0.1 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from hiplot) (7.16.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from hiplot) (4.9.1)\n",
      "Requirement already satisfied: flask-compress in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from hiplot) (1.5.0)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from flask->hiplot) (7.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from flask->hiplot) (1.1.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from flask->hiplot) (2.11.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from flask->hiplot) (0.16.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (4.4.2)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.4.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (4.3.3)\n",
      "Requirement already satisfied: pygments in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (2.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (3.0.7)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (49.6.0.post20200814)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.17.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from beautifulsoup4->hiplot) (2.0.1)\n",
      "Requirement already satisfied: brotli in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from flask-compress->hiplot) (1.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from Jinja2>=2.10.1->flask->hiplot) (1.1.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from traitlets>=4.2->ipython>=7.0.1->hiplot) (0.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from traitlets>=4.2->ipython>=7.0.1->hiplot) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.0.1->hiplot) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\paplu\\anaconda3\\envs\\yolov4\\lib\\site-packages (from jedi>=0.10->ipython>=7.0.1->hiplot) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner\n",
    "!pip install hiplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import kerastuner as kt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dir=\"D:\\params_datasets\\cleaned_data_4_folders\\\\new_automated_folders\\\\traffic_dataset_cleaned\\\\validation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 20000 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(150,150),\n",
    "                                                        batch_size=64,\n",
    "                                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "validation done\n"
     ]
    }
   ],
   "source": [
    "print(\"validation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def model_builder(hp):\n",
    "  #------Tuning for Image Augumentation------\n",
    "  global train_datagen\n",
    "  train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   zoom_range=hp.Float('zoom_range',\n",
    "                                                        min_value=0.0,\n",
    "                                                        max_value=0.5,\n",
    "                                                        default=0.05,\n",
    "                                                        step=0.05\n",
    "                                                      ),\n",
    "                                   width_shift_range=hp.Float('width_shift_range',\n",
    "                                                        min_value=0.0,\n",
    "                                                        max_value=0.5,\n",
    "                                                        default=0.05,\n",
    "                                                        step=0.05\n",
    "                                                      ),\n",
    "                                   height_shift_range=hp.Float('height_shift_range',\n",
    "                                                        min_value=0.0,\n",
    "                                                        max_value=0.5,\n",
    "                                                        default=0.05,\n",
    "                                                        step=0.05\n",
    "                                                      ),\n",
    "                                   shear_range=hp.Float('shear_range',\n",
    "                                                        min_value=0.0,\n",
    "                                                        max_value=0.5,\n",
    "                                                        default=0.05,\n",
    "                                                        step=0.05\n",
    "                                                      ),\n",
    "                                   vertical_flip=hp.Choice('vertical_flip',\n",
    "                                                            values=[True,False],\n",
    "                                                            default=True),\n",
    "                                   fill_mode=\"nearest\") \n",
    "\n",
    "  #------Tuning for number of 2D-CNN blocks-------\n",
    "\n",
    "  num_block = hp.Int('num_block', min_value=2, max_value=10, step=1)\n",
    "\n",
    "  num_filters=[]\n",
    "  for i in range(num_block):\n",
    "    num_filters.append(hp.Int(f'num_filters_{str(i)}', min_value=32, max_value=128, step=32))\n",
    "\n",
    "  dropout=[]\n",
    "  for j in range(num_block):\n",
    "    dropout.append(hp.Float(f'dropout_{str(j)}',min_value=0.0,max_value=0.5,default=0.25,step=0.05))\n",
    "\n",
    "  # num_filters = hp.Int('num_filters', min_value=32, max_value=128, step=32)\n",
    "  model = keras.Sequential()\n",
    "  model.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=num_filters[0],\n",
    "                kernel_size=3,\n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                input_shape=(150,150,3)\n",
    "            )\n",
    "        )\n",
    "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "  model.add(\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=dropout[0]\n",
    "            )\n",
    "        )\n",
    "  for i in range(1,num_block):\n",
    "    model.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=num_filters[i],\n",
    "                kernel_size=3,\n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "            )\n",
    "        )\n",
    "    # model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(\n",
    "            tf.keras.layers.Dropout(\n",
    "                rate=dropout[i]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        #flattening\n",
    "\n",
    "\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "\n",
    "  #------tuning for number of Dense layers---------\n",
    "  dence_block = hp.Int('dence_block', min_value=2, max_value=6, step=1)\n",
    "  layer_Neurons=[]\n",
    "  dense_activation=[]\n",
    "  for i in range(dence_block):\n",
    "    layer_Neurons.append(hp.Int(f'layer_Neurons_{str(i)}',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ))\n",
    "    dense_activation.append(hp.Choice(f'dense_activation_{str(i)}',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                ))\n",
    "        #dense_layer_1\n",
    "  for i in range(dence_block):\n",
    "    model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                units=layer_Neurons[i],\n",
    "                activation=dense_activation[i]\n",
    "            )\n",
    "        )  \n",
    "  model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "#------tuning for Learning rate---------\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "modelling done\n"
     ]
    }
   ],
   "source": [
    "print(\"modelling done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "tuner = RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=25,\n",
    "    executions_per_trial=3,\n",
    "    directory=\"D:\\params_datasets\\cleaned_data_4_folders\\\\new_automated_folders\\\\traffic_dataset_cleaned\\\\tuning_results\",\n",
    "    project_name='logs_and_checkpoints')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 391486 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir=\"D:\\params_datasets\\cleaned_data_4_folders\\\\new_automated_folders\\\\traffic_dataset_cleaned\\\\train\"\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150,150),\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildModel(hp)\n",
    "# model = tf.keras.models.load_model('ModelCheckPoint\\ckpt.hdf5')\n",
    "# do this for resuming training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path=\"D:\\params_datasets\\cleaned_data_4_folders\\\\new_automated_folders\\\\traffic_dataset_cleaned\\\\tuning_results\\checkpoint_path\\\\model{epoch:08d}.hdf5\"\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_best_only=True, save_weights_only=False, verbose=1),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"D:\\params_datasets\\cleaned_data_4_folders\\\\new_automated_folders\\\\traffic_dataset_cleaned\\\\tuning_results\\\\tensorboard_log_dir\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_generator,\n",
    "             steps_per_epoch=391486// 3913,\n",
    "             epochs=30,\n",
    "             validation_data=validation_generator,\n",
    "             validation_steps=20000 // 1333,\n",
    "             verbose=1,\n",
    "             callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}